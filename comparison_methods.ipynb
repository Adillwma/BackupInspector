{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_files_reference: 14030\n",
      "total_files_target: 14030\n",
      "left_only_total: 0\n",
      "right_only_total: 0\n",
      "diff_files_total: 0\n",
      "same_files_total: 14030\n",
      "percentage_same: 100.0\n",
      "percentage_missing: 0.0\n",
      "missing_files_list: []\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import filecmp\n",
    "import hashlib\n",
    "\n",
    "class BackupInspectorClass:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def compare_directories(self, refrence_directory, target_directory):\n",
    "        comparison = filecmp.dircmp(refrence_directory, target_directory, ignore=None)\n",
    "\n",
    "        self.left_only_total += len(comparison.left_only)\n",
    "        self.right_only_total += len(comparison.right_only)\n",
    "        self.diff_files_total += len(comparison.diff_files)\n",
    "        self.same_files_total += len(comparison.same_files)\n",
    "\n",
    "        for filename in comparison.left_only:\n",
    "            missing_files_list.append(os.path.join(refrence_directory, filename))        # must be faster way to tdo this than looping through as it is just taking  alsit to another list and appending constant string to begibg of each entry in list, similarly below\n",
    "\n",
    "        if self.hash_choice != \"None\":                                    # PROBABLOY QUICKER TO REMOVE THIS AND JUST DIRECTLY DO HASH CHECK AT HIS POINT RATHER THAN AFTER ALL DIRECTORIES HAVE BEEN COMPARED\n",
    "            for filename in comparison.same_files:  \n",
    "                self.possible_match_list_refrence.append(os.path.join(refrence_directory,filename))            #append filenames of all same_files_total to possible_match_list for checksum scanning\n",
    "                self.possible_match_list_target.append(os.path.join(target_directory,filename))              #append filenames of all same_files_total to possible_match_list for checksum scanning\n",
    "\n",
    "        # Recursively compare subdirectories\n",
    "        for subdirname in comparison.common_dirs:\n",
    "            self.compare_directories(os.path.join(refrence_directory, subdirname), os.path.join(target_directory, subdirname))\n",
    "\n",
    "        return left_only_total, right_only_total, diff_files_total, same_files_total\n",
    "\n",
    "    def hash(self, file_path):\n",
    "\n",
    "        # Initialize MD5 or SHA-1 hash object.\n",
    "        if self.hash_choice == \"Md5\":\n",
    "            hash_operator = hashlib.md5()\n",
    "        elif self.hash_choice == \"Sha1\":\n",
    "            hash_operator = hashlib.sha1()\n",
    "        \n",
    "        # Calculate hashes for the files\n",
    "            with open(file_path, 'rb') as file:\n",
    "                while True:\n",
    "                    data = file.read(8192)  # Read data in chunks.\n",
    "                    if not data:\n",
    "                        break\n",
    "                    hash_operator.update(data)\n",
    "\n",
    "        return hash_operator.hexdigest()\n",
    "\n",
    "    def checksum_comparison(self):\n",
    "        # Iterate through the list of possible matches.\n",
    "        for reference_path, target_path in zip(possible_match_list_refrence, possible_match_list_target):\n",
    "            \n",
    "            reference_hash = hash(reference_path)\n",
    "            target_hash = hash(target_path)\n",
    "            \n",
    "            # If hashes DO NOT match\n",
    "            if reference_hash != target_hash:\n",
    "                print(f\"Files don't match: {reference_path} and {target_path}\")\n",
    "                # Add the reference path to the list of missing files.\n",
    "                missing_files_list.append(reference_path)\n",
    "                # add one to the count of diff files and one to the left only total\n",
    "                self.diff_files_total += 1\n",
    "                self.left_only_total += 1\n",
    "\n",
    "                # remove the reference and target  paths from thier respective lists of possible matches\n",
    "                possible_match_list_refrence.remove(reference_path)\n",
    "                possible_match_list_target.remove(target_path)\n",
    "                # remove one from the count of same files\n",
    "                self.same_files_total -= 1\n",
    "\n",
    "    def run(self, reference_dirs, target_dirs, hash_choice):\n",
    "        self.hash_choice = hash_choice\n",
    "        self.left_only_total = 0\n",
    "        self.right_only_total = 0\n",
    "        self.diff_files_total = 0\n",
    "        self.same_files_total = 0\n",
    "        self.possible_match_list_refrence = []\n",
    "        self.possible_match_list_target = []\n",
    "        self.missing_files_list = []\n",
    "\n",
    "        for reference_directory, target_directory in zip(reference_dirs, target_dirs):\n",
    "            self.compare_directories(reference_directory, target_directory)\n",
    "\n",
    "        if hash_choice != \"None\":\n",
    "            self.checksum_comparison()\n",
    "\n",
    "        # Calculate the total number of files in the reference and target directories.\n",
    "        total_files_reference = self.left_only_total + self.same_files_total\n",
    "        total_files_target = self.right_only_total + self.same_files_total\n",
    "\n",
    "        # Calculate the percentage of files missing from the target directory.\n",
    "        percentage_missing = round((self.left_only_total / total_files_reference) * 100, 2)\n",
    "\n",
    "        # Calculate the percentage of files that are the same between the reference and target directories.\n",
    "        percentage_same = round((self.same_files_total / total_files_reference) * 100, 2)\n",
    "\n",
    "        return self.left_only_total, self.right_only_total, self.diff_files_total, self.same_files_total, self.missing_files_list, total_files_reference, total_files_target, percentage_missing, percentage_same\n",
    "    \n",
    "\n",
    "# Example usage:\n",
    "reference_directory = [r\"A:\\Users\\Ada\\Desktop\", r\"A:\\Users\\Ada\\Desktop\"]\n",
    "target_directory = [r\"A:\\Users\\Ada\\Desktop\", r\"A:\\Users\\Ada\\Desktop\"]\n",
    "hash_choice = \"Md5\"\n",
    "\n",
    "backup_inspector = BackupInspectorClass()\n",
    "left_only_total, right_only_total, diff_files_total, same_files_total, missing_files_list, total_files_reference, total_files_target, percentage_missing, percentage_same = backup_inspector.run(reference_directory, target_directory, hash_choice)\n",
    "\n",
    "print(f\"total_files_reference: {total_files_reference}\")\n",
    "print(f\"total_files_target: {total_files_target}\")\n",
    "print(f\"left_only_total: {left_only_total}\")\n",
    "print(f\"right_only_total: {right_only_total}\")\n",
    "print(f\"diff_files_total: {diff_files_total}\")\n",
    "print(f\"same_files_total: {same_files_total}\")\n",
    "print(f\"percentage_same: {percentage_same}\")\n",
    "print(f\"percentage_missing: {percentage_missing}\")\n",
    "print(f\"missing_files_list: {missing_files_list}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hash Choice: None\n",
      "Execution Time: 238.9262598999776 seconds\n",
      "\n",
      "Hash Choice: Md5\n",
      "Execution Time: 251.22141569998348 seconds\n",
      "\n",
      "Hash Choice: SHA-1\n",
      "Execution Time: 258.2752649000031 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "\n",
    "def run_backup_inspector(hash_choice):\n",
    "    backup_inspector = BackupInspectorClass()\n",
    "    left_only_total, right_only_total, diff_files_total, same_files_total, missing_files_list = backup_inspector.run(reference_directory, target_directory, hash_choice)\n",
    "\n",
    "# Define the reference_directory and target_directory variables\n",
    "\n",
    "hash_choices = [\"None\", \"Md5\", \"SHA-1\"]\n",
    "\n",
    "for hash_choice in hash_choices:\n",
    "    stmt = f\"run_backup_inspector('{hash_choice}')\"\n",
    "    setup = \"from __main__ import run_backup_inspector\"\n",
    "    \n",
    "    # Time the execution of the code\n",
    "    execution_time = timeit.timeit(stmt, setup, number=100)\n",
    "    \n",
    "    print(f\"Hash Choice: {hash_choice}\")\n",
    "    print(f\"Execution Time: {execution_time} seconds\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
